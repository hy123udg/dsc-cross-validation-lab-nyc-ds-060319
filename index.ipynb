{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = pd.DataFrame(boston.target,columns = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 102 404 102\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = linreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = result.predict(x_train)\n",
    "y_hat_test = result.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE = mse(y_train, y_hat_train)\n",
    "test_MSE = mse(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.652349660324546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.384562770971797"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers\n",
    "    data = pd.DataFrame(data)\n",
    "    fold_size = len(data)//k\n",
    "    remainder = len(data)%k\n",
    "    folds = []\n",
    "    start = 0\n",
    "    for i in range(0,len(data), fold_size):\n",
    "        if len(data) - i < fold_size:\n",
    "            count = 0\n",
    "            for j in range(start,len(data)):\n",
    "                folds[count].append(data.iloc[start+count,:])\n",
    "                count += 1\n",
    "        else:\n",
    "            folds.append(data[start:start + fold_size])\n",
    "            start += fold_size\n",
    "            \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to concatenate the data again\n",
    "len(bos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_data = pd.concat([X.reset_index(drop=True), y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = kfolds(bos_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2ec01bffbe53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Fit a linear regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Evaluate Train and Test Errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2487\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2489\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = pd.concat(fold for i, fold in enumerate(folds) if i != n)\n",
    "    test = folds[n]\n",
    "    # Fit a linear regression model\n",
    "    model = linreg.fit(train[:,:-1], train[:,-1])\n",
    "    #Evaluate Train and Test Errors\n",
    "\n",
    "# print(train_errs)\n",
    "# print(test_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.781</td>\n",
       "      <td>0.390808</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>-0.555806</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.405</td>\n",
       "      <td>0.369415</td>\n",
       "      <td>0.177720</td>\n",
       "      <td>-0.012136</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.137</td>\n",
       "      <td>0.369415</td>\n",
       "      <td>0.993873</td>\n",
       "      <td>0.378596</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.167</td>\n",
       "      <td>0.321174</td>\n",
       "      <td>0.989384</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.851</td>\n",
       "      <td>0.262627</td>\n",
       "      <td>0.992814</td>\n",
       "      <td>0.717270</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.836</td>\n",
       "      <td>0.282946</td>\n",
       "      <td>0.996898</td>\n",
       "      <td>0.925237</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.127</td>\n",
       "      <td>0.265716</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.457274</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.474</td>\n",
       "      <td>0.323240</td>\n",
       "      <td>0.995814</td>\n",
       "      <td>0.226874</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.229</td>\n",
       "      <td>0.342236</td>\n",
       "      <td>0.985703</td>\n",
       "      <td>0.621518</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.195</td>\n",
       "      <td>0.379096</td>\n",
       "      <td>0.991401</td>\n",
       "      <td>0.323147</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>0.363602</td>\n",
       "      <td>0.996697</td>\n",
       "      <td>-0.087468</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.913</td>\n",
       "      <td>0.309243</td>\n",
       "      <td>0.995083</td>\n",
       "      <td>0.690763</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.092</td>\n",
       "      <td>0.342715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778828</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.254</td>\n",
       "      <td>0.291528</td>\n",
       "      <td>0.979424</td>\n",
       "      <td>-0.040585</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.928</td>\n",
       "      <td>0.328438</td>\n",
       "      <td>0.868904</td>\n",
       "      <td>0.643864</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.176</td>\n",
       "      <td>0.371798</td>\n",
       "      <td>0.990922</td>\n",
       "      <td>0.195352</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.021</td>\n",
       "      <td>0.374460</td>\n",
       "      <td>0.993973</td>\n",
       "      <td>-0.064670</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.872</td>\n",
       "      <td>0.330894</td>\n",
       "      <td>0.853069</td>\n",
       "      <td>0.602122</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.376265</td>\n",
       "      <td>0.986384</td>\n",
       "      <td>0.399535</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.870</td>\n",
       "      <td>0.291752</td>\n",
       "      <td>0.980458</td>\n",
       "      <td>0.490053</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.004</td>\n",
       "      <td>0.280347</td>\n",
       "      <td>0.951510</td>\n",
       "      <td>0.478420</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.961</td>\n",
       "      <td>0.258609</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.858758</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.856</td>\n",
       "      <td>0.228811</td>\n",
       "      <td>0.932952</td>\n",
       "      <td>1.439583</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.879</td>\n",
       "      <td>0.242015</td>\n",
       "      <td>0.955822</td>\n",
       "      <td>0.825919</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.986</td>\n",
       "      <td>0.239191</td>\n",
       "      <td>0.970044</td>\n",
       "      <td>0.540295</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.613</td>\n",
       "      <td>0.186161</td>\n",
       "      <td>0.905164</td>\n",
       "      <td>1.556654</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.693</td>\n",
       "      <td>0.193552</td>\n",
       "      <td>0.987922</td>\n",
       "      <td>0.788547</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.431</td>\n",
       "      <td>0.199215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604289</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.637</td>\n",
       "      <td>0.236434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896421</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.458</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.995310</td>\n",
       "      <td>0.271085</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.880</td>\n",
       "      <td>0.315516</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.193968</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.572</td>\n",
       "      <td>0.350595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526742</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.416</td>\n",
       "      <td>0.358664</td>\n",
       "      <td>0.996470</td>\n",
       "      <td>-0.282037</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.859</td>\n",
       "      <td>0.367424</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>-0.174987</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.546</td>\n",
       "      <td>0.429699</td>\n",
       "      <td>0.985022</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.020</td>\n",
       "      <td>0.483020</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>-0.095686</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.315</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.996722</td>\n",
       "      <td>-0.886234</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.860</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>0.985804</td>\n",
       "      <td>-0.727222</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.980</td>\n",
       "      <td>0.386791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.255310</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.765</td>\n",
       "      <td>0.373477</td>\n",
       "      <td>0.996621</td>\n",
       "      <td>-0.579869</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.144</td>\n",
       "      <td>0.350887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.155</td>\n",
       "      <td>0.367221</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>-1.329660</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.563</td>\n",
       "      <td>0.389463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.056167</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.604</td>\n",
       "      <td>0.409815</td>\n",
       "      <td>0.985123</td>\n",
       "      <td>0.444218</td>\n",
       "      <td>26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.153</td>\n",
       "      <td>0.449073</td>\n",
       "      <td>0.975314</td>\n",
       "      <td>0.342258</td>\n",
       "      <td>29.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.831</td>\n",
       "      <td>0.438603</td>\n",
       "      <td>0.989233</td>\n",
       "      <td>-1.462710</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.782</td>\n",
       "      <td>0.509845</td>\n",
       "      <td>0.992360</td>\n",
       "      <td>-0.786023</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.556</td>\n",
       "      <td>0.588544</td>\n",
       "      <td>0.964547</td>\n",
       "      <td>-1.422033</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.185</td>\n",
       "      <td>0.588544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.143466</td>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.951</td>\n",
       "      <td>0.735961</td>\n",
       "      <td>0.951536</td>\n",
       "      <td>-1.235596</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.739</td>\n",
       "      <td>0.735961</td>\n",
       "      <td>0.981870</td>\n",
       "      <td>-1.375206</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.178</td>\n",
       "      <td>0.735961</td>\n",
       "      <td>0.983837</td>\n",
       "      <td>-2.193335</td>\n",
       "      <td>36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.800</td>\n",
       "      <td>0.718694</td>\n",
       "      <td>0.991099</td>\n",
       "      <td>-1.258618</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.604</td>\n",
       "      <td>0.718694</td>\n",
       "      <td>0.949065</td>\n",
       "      <td>-1.489123</td>\n",
       "      <td>29.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.875</td>\n",
       "      <td>0.678108</td>\n",
       "      <td>0.993267</td>\n",
       "      <td>-2.136280</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.287</td>\n",
       "      <td>0.786695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.607317</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.107</td>\n",
       "      <td>0.786695</td>\n",
       "      <td>0.892607</td>\n",
       "      <td>-0.363221</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.274</td>\n",
       "      <td>0.786695</td>\n",
       "      <td>0.988149</td>\n",
       "      <td>-0.801053</td>\n",
       "      <td>34.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.975</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.422033</td>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.135</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>0.968228</td>\n",
       "      <td>-1.462710</td>\n",
       "      <td>32.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAS     RM       DIS         B     LSTAT  target\n",
       "101   0.0  6.781  0.390808  0.996672 -0.555806    26.5\n",
       "102   0.0  6.405  0.369415  0.177720 -0.012136    18.6\n",
       "103   0.0  6.137  0.369415  0.993873  0.378596    19.3\n",
       "104   0.0  6.167  0.321174  0.989384  0.235000    20.1\n",
       "105   0.0  5.851  0.262627  0.992814  0.717270    19.5\n",
       "106   0.0  5.836  0.282946  0.996898  0.925237    19.5\n",
       "107   0.0  6.127  0.265716  0.976776  0.457274    20.4\n",
       "108   0.0  6.474  0.323240  0.995814  0.226874    19.8\n",
       "109   0.0  6.229  0.342236  0.985703  0.621518    19.4\n",
       "110   0.0  6.195  0.379096  0.991401  0.323147    21.7\n",
       "111   0.0  6.715  0.363602  0.996697 -0.087468    22.8\n",
       "112   0.0  5.913  0.309243  0.995083  0.690763    18.8\n",
       "113   0.0  6.092  0.342715  1.000000  0.778828    18.7\n",
       "114   0.0  6.254  0.291528  0.979424 -0.040585    18.5\n",
       "115   0.0  5.928  0.328438  0.868904  0.643864    18.3\n",
       "116   0.0  6.176  0.371798  0.990922  0.195352    21.2\n",
       "117   0.0  6.021  0.374460  0.993973 -0.064670    19.2\n",
       "118   0.0  5.872  0.330894  0.853069  0.602122    20.4\n",
       "119   0.0  5.731  0.376265  0.986384  0.399535    19.3\n",
       "120   0.0  5.870  0.291752  0.980458  0.490053    22.0\n",
       "121   0.0  6.004  0.280347  0.951510  0.478420    20.3\n",
       "122   0.0  5.961  0.258609  0.952569  0.858758    20.5\n",
       "123   0.0  5.856  0.228811  0.932952  1.439583    17.3\n",
       "124   0.0  5.879  0.242015  0.955822  0.825919    18.8\n",
       "125   0.0  5.986  0.239191  0.970044  0.540295    21.4\n",
       "126   0.0  5.613  0.186161  0.905164  1.556654    15.7\n",
       "127   0.0  5.693  0.193552  0.987922  0.788547    16.2\n",
       "128   0.0  6.431  0.199215  1.000000  0.604289    18.0\n",
       "129   0.0  5.637  0.236434  1.000000  0.896421    14.3\n",
       "130   0.0  6.458  0.264941  0.995310  0.271085    19.2\n",
       "..    ...    ...       ...       ...       ...     ...\n",
       "171   0.0  5.880  0.315516  0.877024  0.193968    19.1\n",
       "172   0.0  5.572  0.350595  1.000000  0.526742    23.1\n",
       "173   0.0  6.416  0.358664  0.996470 -0.282037    23.6\n",
       "174   0.0  5.859  0.367424  0.990746 -0.174987    22.6\n",
       "175   0.0  6.546  0.429699  0.985022 -1.162114    29.4\n",
       "176   0.0  6.020  0.483020  0.990746 -0.095686    23.2\n",
       "177   0.0  6.315  0.453901  0.996722 -0.886234    24.6\n",
       "178   0.0  6.860  0.399451  0.985804 -0.727222    29.9\n",
       "179   0.0  6.980  0.386791  1.000000 -1.255310    37.2\n",
       "180   0.0  7.765  0.373477  0.996621 -0.579869    39.8\n",
       "181   0.0  6.144  0.350887  1.000000 -0.208148    36.2\n",
       "182   0.0  7.155  0.367221  0.992990 -1.329660    37.9\n",
       "183   0.0  6.563  0.389463  1.000000 -1.056167    32.5\n",
       "184   0.0  5.604  0.409815  0.985123  0.444218    26.4\n",
       "185   0.0  6.153  0.449073  0.975314  0.342258    29.6\n",
       "186   0.0  7.831  0.438603  0.989233 -1.462710    50.0\n",
       "187   0.0  6.782  0.509845  0.992360 -0.786023    32.0\n",
       "188   0.0  6.556  0.588544  0.964547 -1.422033    29.8\n",
       "189   0.0  7.185  0.588544  1.000000 -1.143466    34.9\n",
       "190   0.0  6.951  0.735961  0.951536 -1.235596    37.0\n",
       "191   0.0  6.739  0.735961  0.981870 -1.375206    30.5\n",
       "192   0.0  7.178  0.735961  0.983837 -2.193335    36.4\n",
       "193   0.0  6.800  0.718694  0.991099 -1.258618    31.1\n",
       "194   0.0  6.604  0.718694  0.949065 -1.489123    29.1\n",
       "195   0.0  7.875  0.678108  0.993267 -2.136280    50.0\n",
       "196   0.0  7.287  0.786695  1.000000 -1.607317    33.3\n",
       "197   0.0  7.107  0.786695  0.892607 -0.363221    30.3\n",
       "198   0.0  7.274  0.786695  0.988149 -0.801053    34.6\n",
       "199   0.0  6.975  0.806093  1.000000 -1.422033    34.9\n",
       "200   0.0  7.135  0.806093  0.968228 -1.462710    32.9\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[1][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
