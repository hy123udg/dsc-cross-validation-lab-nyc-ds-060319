{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = pd.DataFrame(boston.target,columns = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 102 404 102\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = linreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = result.predict(x_train)\n",
    "y_hat_test = result.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE = mse(y_train, y_hat_train)\n",
    "test_MSE = mse(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.652349660324546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.384562770971797"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers\n",
    "    data = pd.DataFrame(data)\n",
    "    fold_size = len(data)//k\n",
    "    remainder = len(data)%k\n",
    "    folds = []\n",
    "    start = 0\n",
    "    for i in range(0,len(data), fold_size):\n",
    "        if len(data) - i < fold_size:\n",
    "            count = 0\n",
    "            for j in range(start,len(data)):\n",
    "                folds[count].append(data.iloc[start+count,:])\n",
    "                count += 1\n",
    "        else:\n",
    "            folds.append(data[start:start + fold_size])\n",
    "            start += fold_size\n",
    "            \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to concatenate the data again\n",
    "len(bos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_data = pd.concat([X.reset_index(drop=True), y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = kfolds(bos_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d425d99a2548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Fit a linear regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Evaluate Train and Test Errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = pd.concat(fold for i, fold in enumerate(folds) if i != n)\n",
    "    test = folds[n]\n",
    "    # Fit a linear regression model\n",
    "    model = linreg.fit(train[:-1], train[-1])\n",
    "    #Evaluate Train and Test Errors\n",
    "\n",
    "# print(train_errs)\n",
    "# print(test_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.781</td>\n",
       "      <td>0.390808</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>-0.555806</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.405</td>\n",
       "      <td>0.369415</td>\n",
       "      <td>0.177720</td>\n",
       "      <td>-0.012136</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.137</td>\n",
       "      <td>0.369415</td>\n",
       "      <td>0.993873</td>\n",
       "      <td>0.378596</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.167</td>\n",
       "      <td>0.321174</td>\n",
       "      <td>0.989384</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.851</td>\n",
       "      <td>0.262627</td>\n",
       "      <td>0.992814</td>\n",
       "      <td>0.717270</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.836</td>\n",
       "      <td>0.282946</td>\n",
       "      <td>0.996898</td>\n",
       "      <td>0.925237</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.127</td>\n",
       "      <td>0.265716</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.457274</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.474</td>\n",
       "      <td>0.323240</td>\n",
       "      <td>0.995814</td>\n",
       "      <td>0.226874</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.229</td>\n",
       "      <td>0.342236</td>\n",
       "      <td>0.985703</td>\n",
       "      <td>0.621518</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.195</td>\n",
       "      <td>0.379096</td>\n",
       "      <td>0.991401</td>\n",
       "      <td>0.323147</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>0.363602</td>\n",
       "      <td>0.996697</td>\n",
       "      <td>-0.087468</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.913</td>\n",
       "      <td>0.309243</td>\n",
       "      <td>0.995083</td>\n",
       "      <td>0.690763</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.092</td>\n",
       "      <td>0.342715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778828</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.254</td>\n",
       "      <td>0.291528</td>\n",
       "      <td>0.979424</td>\n",
       "      <td>-0.040585</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.928</td>\n",
       "      <td>0.328438</td>\n",
       "      <td>0.868904</td>\n",
       "      <td>0.643864</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.176</td>\n",
       "      <td>0.371798</td>\n",
       "      <td>0.990922</td>\n",
       "      <td>0.195352</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.021</td>\n",
       "      <td>0.374460</td>\n",
       "      <td>0.993973</td>\n",
       "      <td>-0.064670</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.872</td>\n",
       "      <td>0.330894</td>\n",
       "      <td>0.853069</td>\n",
       "      <td>0.602122</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.376265</td>\n",
       "      <td>0.986384</td>\n",
       "      <td>0.399535</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.870</td>\n",
       "      <td>0.291752</td>\n",
       "      <td>0.980458</td>\n",
       "      <td>0.490053</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.004</td>\n",
       "      <td>0.280347</td>\n",
       "      <td>0.951510</td>\n",
       "      <td>0.478420</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.961</td>\n",
       "      <td>0.258609</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.858758</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.856</td>\n",
       "      <td>0.228811</td>\n",
       "      <td>0.932952</td>\n",
       "      <td>1.439583</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.879</td>\n",
       "      <td>0.242015</td>\n",
       "      <td>0.955822</td>\n",
       "      <td>0.825919</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.986</td>\n",
       "      <td>0.239191</td>\n",
       "      <td>0.970044</td>\n",
       "      <td>0.540295</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.613</td>\n",
       "      <td>0.186161</td>\n",
       "      <td>0.905164</td>\n",
       "      <td>1.556654</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.693</td>\n",
       "      <td>0.193552</td>\n",
       "      <td>0.987922</td>\n",
       "      <td>0.788547</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.431</td>\n",
       "      <td>0.199215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604289</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.637</td>\n",
       "      <td>0.236434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896421</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.458</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.995310</td>\n",
       "      <td>0.271085</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.427</td>\n",
       "      <td>0.322703</td>\n",
       "      <td>0.888244</td>\n",
       "      <td>0.878155</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.162</td>\n",
       "      <td>0.281992</td>\n",
       "      <td>0.762620</td>\n",
       "      <td>1.351408</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.484</td>\n",
       "      <td>0.300543</td>\n",
       "      <td>0.998260</td>\n",
       "      <td>0.927021</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.304</td>\n",
       "      <td>0.261386</td>\n",
       "      <td>0.880428</td>\n",
       "      <td>1.406477</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.185</td>\n",
       "      <td>0.275157</td>\n",
       "      <td>0.956629</td>\n",
       "      <td>0.868023</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.229</td>\n",
       "      <td>0.230282</td>\n",
       "      <td>0.965757</td>\n",
       "      <td>0.337183</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.242</td>\n",
       "      <td>0.467238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.750</td>\n",
       "      <td>0.455701</td>\n",
       "      <td>0.990342</td>\n",
       "      <td>-0.540671</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.061</td>\n",
       "      <td>0.465562</td>\n",
       "      <td>0.995915</td>\n",
       "      <td>-0.705696</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.762</td>\n",
       "      <td>0.542950</td>\n",
       "      <td>0.989964</td>\n",
       "      <td>-0.045374</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.871</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.934011</td>\n",
       "      <td>0.366155</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.312</td>\n",
       "      <td>0.531847</td>\n",
       "      <td>0.979121</td>\n",
       "      <td>-0.019990</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.114</td>\n",
       "      <td>0.481952</td>\n",
       "      <td>0.989359</td>\n",
       "      <td>0.559308</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.905</td>\n",
       "      <td>0.432381</td>\n",
       "      <td>0.978113</td>\n",
       "      <td>0.111652</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.454</td>\n",
       "      <td>0.201163</td>\n",
       "      <td>0.995436</td>\n",
       "      <td>0.870793</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.414</td>\n",
       "      <td>0.185729</td>\n",
       "      <td>0.866736</td>\n",
       "      <td>1.342398</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.093</td>\n",
       "      <td>0.201557</td>\n",
       "      <td>0.802133</td>\n",
       "      <td>1.698339</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.983</td>\n",
       "      <td>0.211945</td>\n",
       "      <td>0.982879</td>\n",
       "      <td>0.871715</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.983</td>\n",
       "      <td>0.263227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.707</td>\n",
       "      <td>0.314279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191196</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.926</td>\n",
       "      <td>0.314279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397085</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.670</td>\n",
       "      <td>0.382239</td>\n",
       "      <td>0.990897</td>\n",
       "      <td>0.827813</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.390</td>\n",
       "      <td>0.382239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.133108</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.794</td>\n",
       "      <td>0.396172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458456</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.019</td>\n",
       "      <td>0.319098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312864</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.569</td>\n",
       "      <td>0.317486</td>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.027</td>\n",
       "      <td>0.334399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485410</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.593</td>\n",
       "      <td>0.331081</td>\n",
       "      <td>0.987619</td>\n",
       "      <td>-0.169811</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.120</td>\n",
       "      <td>0.297277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.274682</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.976</td>\n",
       "      <td>0.274575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.067939</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAS     RM       DIS         B     LSTAT  target\n",
       "101   0.0  6.781  0.390808  0.996672 -0.555806    26.5\n",
       "102   0.0  6.405  0.369415  0.177720 -0.012136    18.6\n",
       "103   0.0  6.137  0.369415  0.993873  0.378596    19.3\n",
       "104   0.0  6.167  0.321174  0.989384  0.235000    20.1\n",
       "105   0.0  5.851  0.262627  0.992814  0.717270    19.5\n",
       "106   0.0  5.836  0.282946  0.996898  0.925237    19.5\n",
       "107   0.0  6.127  0.265716  0.976776  0.457274    20.4\n",
       "108   0.0  6.474  0.323240  0.995814  0.226874    19.8\n",
       "109   0.0  6.229  0.342236  0.985703  0.621518    19.4\n",
       "110   0.0  6.195  0.379096  0.991401  0.323147    21.7\n",
       "111   0.0  6.715  0.363602  0.996697 -0.087468    22.8\n",
       "112   0.0  5.913  0.309243  0.995083  0.690763    18.8\n",
       "113   0.0  6.092  0.342715  1.000000  0.778828    18.7\n",
       "114   0.0  6.254  0.291528  0.979424 -0.040585    18.5\n",
       "115   0.0  5.928  0.328438  0.868904  0.643864    18.3\n",
       "116   0.0  6.176  0.371798  0.990922  0.195352    21.2\n",
       "117   0.0  6.021  0.374460  0.993973 -0.064670    19.2\n",
       "118   0.0  5.872  0.330894  0.853069  0.602122    20.4\n",
       "119   0.0  5.731  0.376265  0.986384  0.399535    19.3\n",
       "120   0.0  5.870  0.291752  0.980458  0.490053    22.0\n",
       "121   0.0  6.004  0.280347  0.951510  0.478420    20.3\n",
       "122   0.0  5.961  0.258609  0.952569  0.858758    20.5\n",
       "123   0.0  5.856  0.228811  0.932952  1.439583    17.3\n",
       "124   0.0  5.879  0.242015  0.955822  0.825919    18.8\n",
       "125   0.0  5.986  0.239191  0.970044  0.540295    21.4\n",
       "126   0.0  5.613  0.186161  0.905164  1.556654    15.7\n",
       "127   0.0  5.693  0.193552  0.987922  0.788547    16.2\n",
       "128   0.0  6.431  0.199215  1.000000  0.604289    18.0\n",
       "129   0.0  5.637  0.236434  1.000000  0.896421    14.3\n",
       "130   0.0  6.458  0.264941  0.995310  0.271085    19.2\n",
       "..    ...    ...       ...       ...       ...     ...\n",
       "474   0.0  5.427  0.322703  0.888244  0.878155    13.8\n",
       "475   0.0  6.162  0.281992  0.762620  1.351408    13.3\n",
       "476   0.0  6.484  0.300543  0.998260  0.927021    16.7\n",
       "477   0.0  5.304  0.261386  0.880428  1.406477    12.0\n",
       "478   0.0  6.185  0.275157  0.956629  0.868023    14.6\n",
       "479   0.0  6.229  0.230282  0.965757  0.337183    21.4\n",
       "480   0.0  6.242  0.467238  1.000000  0.005014    23.0\n",
       "481   0.0  6.750  0.455701  0.990342 -0.540671    23.7\n",
       "482   0.0  7.061  0.465562  0.995915 -0.705696    25.0\n",
       "483   0.0  5.762  0.542950  0.989964 -0.045374    21.8\n",
       "484   0.0  5.871  0.502600  0.934011  0.366155    20.6\n",
       "485   0.0  6.312  0.531847  0.979121 -0.019990    21.2\n",
       "486   0.0  6.114  0.481952  0.989359  0.559308    19.1\n",
       "487   0.0  5.905  0.432381  0.978113  0.111652    20.6\n",
       "488   0.0  5.454  0.201163  0.995436  0.870793    15.2\n",
       "489   0.0  5.414  0.185729  0.866736  1.342398     7.0\n",
       "490   0.0  5.093  0.201557  0.802133  1.698339     8.1\n",
       "491   0.0  5.983  0.211945  0.982879  0.871715    13.6\n",
       "492   0.0  5.983  0.263227  1.000000  0.367403    20.1\n",
       "493   0.0  5.707  0.314279  1.000000  0.191196    21.8\n",
       "494   0.0  5.926  0.314279  1.000000  0.397085    24.5\n",
       "495   0.0  5.670  0.382239  0.990897  0.827813    23.1\n",
       "496   0.0  5.390  0.382239  1.000000  1.133108    19.7\n",
       "497   0.0  5.794  0.396172  1.000000  0.458456    18.3\n",
       "498   0.0  6.019  0.319098  1.000000  0.312864    21.2\n",
       "499   0.0  5.569  0.317486  0.997151  0.572599    17.5\n",
       "500   0.0  6.027  0.334399  1.000000  0.485410    16.8\n",
       "501   0.0  6.593  0.331081  0.987619 -0.169811    22.4\n",
       "502   0.0  6.120  0.297277  1.000000 -0.274682    20.6\n",
       "503   0.0  6.976  0.274575  1.000000 -1.067939    23.9\n",
       "\n",
       "[403 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
